
                                                                                                                                        
  データ概要                                                                                                                            
  ┌──────────────┬──────────────────────────────────────┐                                                                               
  │     項目     │                  値                  │                                                                               
  ├──────────────┼──────────────────────────────────────┤                                                                               
  │ 物体数       │ 6（H1-H3: 硬い、S1-S3: 柔らかい）    │                                                                               
  ├──────────────┼──────────────────────────────────────┤                                                                               
  │ トライアル数 │ 76（各物体12-16）                    │                                                                               
  ├──────────────┼──────────────────────────────────────┤                                                                               
  │ 動画サイズ   │ 640×360, 30fps, 約14秒               │                                                                               
  ├──────────────┼──────────────────────────────────────┤                                                                               
  │ 入力         │ gelsight_raw.avi + gelsight_diff.avi │                                                                               
  └──────────────┴──────────────────────────────────────┘                                                                               
  ラベル分布                                                                                                                            
                                                                                                                                        
  H1-H3（硬い物体）: slip多数、crushなし                                                                                                
  S1-S3（柔らかい物体）: slip多数、crushあり（各3トライアル）                                                                           
                                                                                                                                        
  ---                                                                                                                                   
  推奨モデルアーキテクチャ                                                                                                              
                                                                                                                                        
  既存の state_estimation.py を参考に、以下のアプローチを提案します：                                                                   
                                                                                                                                        
  1. 触覚のみCNNモデル（推奨）                                                                                                          
                                                                                                                                        
  入力: raw画像(K枚) + diff画像(K枚)                                                                                                    
          ↓                                                                                                                             
  TactileEncoder(raw) → z_raw (128D)                                                                                                    
  TactileEncoder(diff) → z_diff (128D)                                                                                                  
          ↓                                                                                                                             
      concat → MLP                                                                                                                      
          ↓                                                                                                                             
  出力: p_slip, p_crush                                                                                                                 
                                                                                                                                        
  理由：                                                                                                                                
  - OpenCLIPなしでも触覚情報だけで十分予測可能                                                                                          
  - 既存の TactileEncoder をそのまま活用できる                                                                                          
  - データ量が少ない（76トライアル）ため、シンプルなモデルが適切                                                                        
                                                                                                                                        
  2. フレームサンプリング戦略                                                                                                           
                                                                                                                                        
  meta.json のイベント情報を活用：                                                                                                      
  - contact_start_frame: 接触開始                                                                                                       
  - disturbance_frame: 外乱（引っ張り）                                                                                                 
  - release_frame: リリース                                                                                                             
                                                                                                                                        
  重要なフレーム区間：                                                                                                                  
  - 接触直後 (contact → +30フレーム): 初期グリップ品質                                                                                  
  - 外乱中 (disturbance → +60フレーム): 滑り検出に最重要                                                                                
  - 保持中 (hold): crush検出に重要                                                                                                      
                                                                                                                                        
  3. データ拡張                                                                                                                         
                                                                                                                                        
  データ量が少ないため必須：                                                                                                            
  - ランダムクロップ（640×360 → 224×224など）                                                                                           
  - カラージッター                                                                                                                      
  - 水平反転                                                                                                                            
  - フレームのランダムサンプリング                                                                                                      
                                                                                                                                        
  ---                                                                                                                                   
  具体的な実装案                                                                                                                        
                                                                                                                                        
  タスク別モデル                                                                                                                        
  ┌────────────┬──────────────────┬───────────┬──────────────────┐                                                                      
  │   タスク   │       入力       │   出力    │       特徴       │                                                                      
  ├────────────┼──────────────────┼───────────┼──────────────────┤                                                                      
  │ 滑り検出   │ 外乱中のdiff画像 │ p_slip    │ 動的変化が重要   │                                                                      
  ├────────────┼──────────────────┼───────────┼──────────────────┤                                                                      
  │ つぶれ検出 │ 保持中のraw画像  │ p_crush   │ 静的変形パターン │                                                                      
  ├────────────┼──────────────────┼───────────┼──────────────────┤                                                                      
  │ 成功予測   │ 全期間           │ p_success │ 総合判断         │                                                                      
  └────────────┴──────────────────┴───────────┴──────────────────┘                                                                      
  シーケンスモデル（オプション）                                                                                                        
                                                                                                                                        
  時系列情報を活用したい場合：                                                                                                          
  CNN Encoder → LSTM/GRU → 予測                                                                                                         
  ただし、データ量が少ないため過学習リスクが高い。                                                                                      
                                                                                                                                        
  ---                                                                                                                                   
  次のステップ                                                                                                                          
                                                                                                                                        
  1. 前処理パイプライン構築                                                                                                             
    - 動画からフレーム抽出                                                                                                              
    - 接触後フレームのみを切り出し                                                                                                      
    - 64×64にリサイズ                                                                                                                   
  2. データセット作成                                                                                                                   
    - train/val/test分割（物体単位で分けるとgeneralization評価可能）                                                                    
    - NPZ形式で保存                                                                                                                     
  3. 学習                                                                                                                               
    - 既存の train_tactile_only.py を拡張                                                                                               
    - BCE Loss（slip, crushは二値分類）                                                                                                 
                                                                                                                                        
  既存の前処理スクリプト（preprocessing/）を活用するか、新規に作成しますか？ 


触覚CNNモデル学習パイプライン実装計画                                                                                                  
                                                                                                                                        
 概要                                                                                                                                   
                                                                                                                                        
 data_raw/の6物体（H1-H3,                                                                                                               
 S1-S3）の把持動画から、滑り(slip)・つぶれ(crush)・成功(success)を予測するCNNモデルを学習するパイプラインを新規作成する。               
                                                                                                                                        
 データ構造                                                                                                                             
                                                                                                                                        
 data_raw/                                                                                                                              
 ├── H1/, H2/, H3/  (硬い物体)                                                                                                          
 ├── S1/, S2/, S3/  (柔らかい物体)                                                                                                      
 │   └── trial_XXXX/                                                                                                                    
 │       ├── gelsight_raw.avi   (640x360, 30fps)                                                                                        
 │       ├── gelsight_diff.avi                                                                                                          
 │       ├── meta.json          (contact_start_frame等)                                                                                 
 │       └── labels.json        (slip, crush, success)                                                                                  
                                                                                                                                        
 実装ファイル                                                                                                                           
                                                                                                                                        
 1. 前処理スクリプト                                                                                                                    
                                                                                                                                        
 ファイル: camera_ws/src/grasp_everything/grasp_everything/preprocessing/build_tactile_dataset.py                                       
                                                                                                                                        
 機能:                                                                                                                                  
 - 動画からフレーム抽出（接触開始〜リリース）                                                                                           
 - raw + diff画像をペアでnpz保存                                                                                                        
 - index.csvに全サンプルのメタデータ記録                                                                                                
                                                                                                                                        
 出力形式:                                                                                                                              
 dataset_tactile/                                                                                                                       
 ├── frames/                                                                                                                            
 │   └── {object_id}__{trial_id}__f{frame:06d}.npz                                                                                      
 │       ├── frame_raw: uint8 [H, W, 3]                                                                                                 
 │       ├── frame_diff: uint8 [H, W, 3]                                                                                                
 │       ├── object_id, trial_id, frame_idx                                                                                             
 │       └── slip, crush, success (ラベル)                                                                                              
 ├── index.csv                                                                                                                          
 └── summary.json                                                                                                                       
                                                                                                                                        
 主要パラメータ:                                                                                                                        
 - --size: 出力画像サイズ (default: 128)                                                                                                
 - --stride: フレーム間隔 (default: 5)                                                                                                  
 - --offset: 接触後オフセット (default: 10)                                                                                             
 - --max-frames: トライアル当たり最大フレーム数 (default: 50)                                                                           
                                                                                                                                        
 ---                                                                                                                                    
 2. データセットクラス                                                                                                                  
                                                                                                                                        
 ファイル: camera_ws/src/grasp_everything/grasp_everything/models/tactile_dataset.py                                                    
                                                                                                                                        
 クラス: TactileFrameDataset                                                                                                            
 - index.csvから読み込み                                                                                                                
 - __getitem__: npzロード → Tensor変換                                                                                                  
 - 入力モード: raw_only / diff_only / both (6ch)                                                                                        
 - データ拡張: 水平反転、明るさ変動                                                                                                     
                                                                                                                                        
 ---                                                                                                                                    
 3. CNNモデル                                                                                                                           
                                                                                                                                        
 ファイル: camera_ws/src/grasp_everything/grasp_everything/models/tactile_cnn.py                                                        
                                                                                                                                        
 アーキテクチャ（既存TactileEncoderベース）:                                                                                            
 入力: (B, 6, H, W) [raw 3ch + diff 3ch]                                                                                                
     ↓                                                                                                                                  
 4層CNN (32→64→128→256, stride=2)                                                                                                       
     ↓                                                                                                                                  
 AdaptiveAvgPool2d(1)                                                                                                                   
     ↓                                                                                                                                  
 FC(256 → 128) → ReLU → Dropout                                                                                                         
     ↓                                                                                                                                  
 FC(128 → 3) [slip, crush, success]





## data_collection
```bash
# GelSight起動                                                                                                                        
  ros2 launch grasp_everything camera_bringup.launch.py                                                                                 
# 収集開始                                                                                                                            
  ros2 run grasp_everything crush_collection \                                                                                          
    --ros-args -p object_id:=marshmallow -p softness:=soft 
```
### 操作:                                                                                                                                 
  [Enter] → 録画開始                                                                                                                    
    ↓                                                                                                                                   
  徐々に力を強くする                                                                                                                    
    ↓                                                                                                                                   
  つぶれたら [c] を押す ← これだけ！                                                                                                    
    ↓                                                                                                                                   
  [Enter] → 録画停止                                                                                                                    

  データ構造:                                                                                                                           
  data_crush/                                                                                                                           
  └── marshmallow/                                                                                                                      
      └── trial_0001/                                                                                                                   
          ├── gelsight_raw.avi                                                                                                          
          ├── gelsight_diff.avi                                                                                                         
          ├── meta.json      # crush_frame: 156                                                                                         
          └── labels.json    # crushed: true   

### 前処理
  uv run python src/grasp_everything/grasp_everything/preprocessing/build_crush_dataset.py \                                            
    --data-dir data_crush \                                                                                                             
    --out-dir dataset_crush \                                                                                                           
    --size 128                                                                                                                          
    
### 自動ラベリング:                                                                                                                       
  - frame < crush_frame - 5 → safe (0)                                                                                                  
  - frame > crush_frame + 5 → crush (1)                                                                                                 
  - 境界付近は除外（曖昧なデータを排除）                                                                                                
  ---                                                                                                                                   
### 学習                                                                                                                            
  uv run python src/grasp_everything/grasp_everything/train_crush_detector.py \                                                         
    --data-dir dataset_crush \                                                                                                          
    --epochs 30                                                                                                                         
  出力:                                                                                                                                 
  - runs/crush_detector_XXXXXX/best.pt - 最良モデル                                                                                     
  - F1スコアで評価（不均衡データに対応）  
  ┌────────────────────┬──────────────────────────────────────────────┐                                                                 
  │      ポイント      │                     説明                     │                                                                 
  ├────────────────────┼──────────────────────────────────────────────┤                                                                 
  │ ゆっくり押す       │ 急に押すとつぶれフレームが曖昧に             │                                                                 
  ├────────────────────┼──────────────────────────────────────────────┤                                                                 
  │ つぶれた瞬間に[c]  │ 目視で判断、多少ずれてもOK（margin=5で吸収） │                                                                 
  ├────────────────────┼──────────────────────────────────────────────┤                                                                 
  │ 物体バリエーション │ 10種類以上推奨                               │                                                                 
  ├────────────────────┼──────────────────────────────────────────────┤                                                                 
  │ 1物体20トライアル  │ つぶれる/つぶれないを混ぜる                  │                                                                 
  └────────────────────┴──────────────────────────────────────────────┘                                                                 
  ---                                                                                                                                   
  目標データ量（1日）                                                                                                                   
  ┌─────────────────┬─────────┐                                                                                                         
  │      項目       │  目標   │                                                                                                         
  ├─────────────────┼─────────┤                                                                                                         
  │ 物体数          │ 15種類  │                                                                                                         
  ├─────────────────┼─────────┤                                                                                                         
  │ トライアル/物体 │ 20      │                                                                                                         
  ├─────────────────┼─────────┤                                                                                                         
  │ 合計トライアル  │ 300     │                                                                                                         
  ├─────────────────┼─────────┤                                                                                                         
  │ 予想フレーム数  │ 15,000+ │ 


|     | 柔らかい物体 | トライアル | つぶれた | 潰れなかった |
| --- | ------ | ----- | ---- | ------ |
| 1   | マシュマロ  | 10    | 10   |        |
| 2   | まんじゅう1 | 10    |      |        |
| 3   | まんじゅう2 | 10    |      |        |
| 4   | まんじゅう3 | 10    |      |        |
| 5   | 大福     | 10    |      |        |
| 6   | ミニトマト  | 10    |      |        |
| 7   | 黒スポンジ  | 10    |      |        |
| 8   | 白スポンジ  | 10    |      |        |
| 9   | いちご    | 10    |      |        |
| 10  | ミニトマト  | 10    |      |        |
| 11  | 紙コップ   | 10    |      |        |
| 12  | ペットボトル | 10    |      |        |
| 13  |        | 10    |      |        |
| 14  |        | 10    |      |        |



|     |                |     |     |
| --- | -------------- | --- | --- |
| 1   | marshmallow    | 9   |     |
| 2   | black manju    | 9   |     |
| 4   | bread          | 9   |     |
| 5   | daifuku        | 9   |     |
| 7   | black sponge   | 9   |     |
| 8   | white sponge   | 9   |     |
| 9   | strawberry     |     |     |
| 10  | cherry tomato  | 9   |     |
| 11  | paper cup      | 9   |     |
| 12  | plastic bottle | 9   |     |
|     | stuffed        | 9   |     |



# 修論概要
[[abstract]]